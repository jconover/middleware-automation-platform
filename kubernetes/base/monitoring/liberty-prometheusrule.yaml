# PrometheusRule for Open Liberty Alerting
# Defines alerting rules that Prometheus Operator loads automatically
#
# These rules monitor Liberty application health, JVM performance,
# and request metrics to ensure production reliability.
---
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: liberty-alerts
  labels:
    app: liberty
    component: monitoring
    # Prometheus Operator selector label
    release: prometheus
    # Role label for rule categorization
    role: alert-rules
spec:
  groups:
    # Application Health Alerts
    - name: liberty.health
      interval: 30s
      rules:
        - alert: LibertyServerDown
          expr: up{job="liberty"} == 0
          for: 1m
          labels:
            severity: critical
            component: liberty
          annotations:
            summary: "Liberty server {{ $labels.pod }} is down"
            description: "Liberty pod {{ $labels.pod }} in namespace {{ $labels.namespace }} has been unreachable for more than 1 minute."
            runbook_url: "https://github.com/your-org/runbooks/blob/main/liberty-server-down.md"

        - alert: LibertyHighRestartCount
          expr: increase(kube_pod_container_status_restarts_total{container="liberty"}[1h]) > 3
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "Liberty pod {{ $labels.pod }} restarting frequently"
            description: "Liberty container in pod {{ $labels.pod }} has restarted {{ $value }} times in the last hour."

        - alert: LibertyReadinessFailure
          expr: kube_pod_status_ready{condition="true", pod=~"liberty.*"} == 0
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "Liberty pod {{ $labels.pod }} not ready"
            description: "Liberty pod {{ $labels.pod }} has been in non-ready state for more than 5 minutes."

    # JVM Performance Alerts
    - name: liberty.jvm
      interval: 30s
      rules:
        - alert: LibertyHighHeapUsage
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            100 * memory_usedHeap_bytes{job="liberty", mp_scope="base"}
              / memory_maxHeap_bytes{job="liberty", mp_scope="base"} > 85
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High heap usage on Liberty pod {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} heap usage is {{ $value | printf \"%.1f\" }}% (threshold: 85%)."

        - alert: LibertyCriticalHeapUsage
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            100 * memory_usedHeap_bytes{job="liberty", mp_scope="base"}
              / memory_maxHeap_bytes{job="liberty", mp_scope="base"} > 95
          for: 2m
          labels:
            severity: critical
            component: liberty
          annotations:
            summary: "Critical heap usage on Liberty pod {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} heap usage is {{ $value | printf \"%.1f\" }}% - OOM risk imminent."

        - alert: LibertyHighGCTime
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            rate(gc_time_total_seconds{job="liberty", mp_scope="base"}[5m]) > 0.1
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High GC time on Liberty pod {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} is spending {{ $value | printf \"%.2f\" }} seconds per second in garbage collection."

        - alert: LibertyThreadPoolExhaustion
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          # Liberty mpMetrics-5.0 Thread Pool metric names:
          #   - threadpool_activeThreads (currently active threads)
          #   - threadpool_size (total pool size)
          expr: |
            threadpool_activeThreads{job="liberty", mp_scope="vendor"}
              / threadpool_size{job="liberty", mp_scope="vendor"} > 0.9
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "Thread pool near exhaustion on {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} thread pool is {{ $value | printf \"%.0f\" }}% utilized."

    # Request and Response Alerts
    - name: liberty.requests
      interval: 30s
      rules:
        - alert: LibertyHighErrorRate
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            sum(rate(servlet_request_total{job="liberty", mp_scope="base", status=~"5.."}[5m]))
              / sum(rate(servlet_request_total{job="liberty", mp_scope="base"}[5m])) > 0.05
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High 5xx error rate on Liberty cluster"
            description: "Liberty servers are returning 5xx errors at {{ $value | printf \"%.1f\" }}% rate (threshold: 5%)."

        - alert: LibertyCriticalErrorRate
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            sum(rate(servlet_request_total{job="liberty", mp_scope="base", status=~"5.."}[5m]))
              / sum(rate(servlet_request_total{job="liberty", mp_scope="base"}[5m])) > 0.10
          for: 2m
          labels:
            severity: critical
            component: liberty
          annotations:
            summary: "Critical error rate on Liberty cluster"
            description: "Liberty servers are returning 5xx errors at {{ $value | printf \"%.1f\" }}% rate - immediate attention required."

        - alert: LibertyHighLatency
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            histogram_quantile(0.95,
              sum(rate(servlet_request_elapsedTime_seconds_bucket{job="liberty", mp_scope="base"}[5m])) by (le)
            ) > 2
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High request latency on Liberty cluster"
            description: "95th percentile request latency is {{ $value | printf \"%.2f\" }} seconds (threshold: 2s)."

        - alert: LibertyNoRequests
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            sum(rate(servlet_request_total{job="liberty", mp_scope="base"}[5m])) == 0
          for: 10m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "No requests to Liberty cluster"
            description: "Liberty cluster has not received any requests in the last 10 minutes - possible routing or connectivity issue."

    # Resource Utilization Alerts
    - name: liberty.resources
      interval: 30s
      rules:
        - alert: LibertyHighCPUUsage
          expr: |
            sum(rate(container_cpu_usage_seconds_total{container="liberty"}[5m])) by (pod)
              / sum(container_spec_cpu_quota{container="liberty"} / container_spec_cpu_period{container="liberty"}) by (pod) > 0.9
          for: 10m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High CPU usage on Liberty pod {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} CPU usage is above 90% of its limit for 10 minutes."

        - alert: LibertyHighMemoryUsage
          expr: |
            container_memory_working_set_bytes{container="liberty"}
              / container_spec_memory_limit_bytes{container="liberty"} > 0.9
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High memory usage on Liberty pod {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} is using {{ $value | printf \"%.0f\" }}% of its memory limit."

    # Connection Pool Alerts
    # Liberty mpMetrics-5.0 Connection Pool metric names:
    #   - connectionpool_freeConnections (available connections in the pool)
    #   - connectionpool_managedConnections (total pool size)
    #   - connectionpool_waitTime_total_seconds (cumulative wait time)
    #   - connectionpool_inUseTime_total_seconds (cumulative in-use time)
    - name: liberty.connections
      interval: 30s
      rules:
        - alert: LibertyDatabaseConnectionPoolLow
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          # Uses connectionpool_freeConnections / connectionpool_managedConnections
          expr: |
            connectionpool_freeConnections{job="liberty", mp_scope="vendor"}
              / connectionpool_managedConnections{job="liberty", mp_scope="vendor"} < 0.1
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "Database connection pool running low on {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} has only {{ $value | printf \"%.0f\" }}% free database connections."

        - alert: LibertyConnectionPoolWaitTime
          # MicroProfile Metrics 5.0 uses mp_scope label instead of prefix
          expr: |
            rate(connectionpool_waitTime_total_seconds{job="liberty", mp_scope="vendor"}[5m]) > 1
          for: 5m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High connection pool wait time on {{ $labels.pod }}"
            description: "Applications on {{ $labels.pod }} are waiting {{ $value | printf \"%.2f\" }}s on average for database connections."

        - alert: LibertyDatabaseConnectionFailure
          # High destroy/create ratio indicates connections are failing
          # A healthy pool has minimal destroy events; high ratio means connections are being killed
          # Liberty mpMetrics-5.0: connectionpool_create_total, connectionpool_destroy_total
          expr: |
            (
              rate(connectionpool_destroy_total{job="liberty", mp_scope="vendor"}[5m])
              / (rate(connectionpool_create_total{job="liberty", mp_scope="vendor"}[5m]) + 0.001)
            ) > 0.5
            and rate(connectionpool_destroy_total{job="liberty", mp_scope="vendor"}[5m]) > 0.1
          for: 5m
          labels:
            severity: critical
            component: liberty
          annotations:
            summary: "Database connection failures detected on {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} is experiencing database connection failures. Destroy/create ratio is {{ $value | printf \"%.2f\" }} (>0.5 indicates issues). Check database health, network connectivity, and connection timeout settings."
            runbook_url: "https://github.com/your-org/runbooks/blob/main/liberty-database-connection-failure.md"

        - alert: LibertyDatabaseConnectionPoolExhausted
          # Zero free connections means all connections are in use
          # Liberty mpMetrics-5.0: connectionpool_freeConnections
          expr: |
            connectionpool_freeConnections{job="liberty", mp_scope="vendor"} == 0
            and connectionpool_managedConnections{job="liberty", mp_scope="vendor"} > 0
          for: 2m
          labels:
            severity: critical
            component: liberty
          annotations:
            summary: "Database connection pool exhausted on {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} has zero free database connections. All {{ $labels.datasource }} connections are in use. New requests will queue or fail. Consider increasing pool size or investigating slow queries."
            runbook_url: "https://github.com/your-org/runbooks/blob/main/liberty-connection-pool-exhausted.md"

        - alert: LibertyDatabaseQueuedRequestsHigh
          # Requests are queuing for connections when pool is saturated
          # Liberty mpMetrics-5.0: connectionpool_queuedRequests (gauge of currently queued)
          # or connectionpool_queuedRequests_total (counter) - use rate on counter
          expr: |
            connectionpool_queuedRequests{job="liberty", mp_scope="vendor"} > 5
          for: 2m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "Database connection requests queuing on {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} has {{ $value | printf \"%.0f\" }} requests waiting for database connections. This indicates connection pool saturation. Consider increasing maxPoolSize or optimizing database queries."
            runbook_url: "https://github.com/your-org/runbooks/blob/main/liberty-connection-queue-high.md"

        - alert: LibertyDatabaseConnectionChurn
          # High connection creation rate indicates pool instability
          # Could mean connections are timing out or being invalidated frequently
          # Liberty mpMetrics-5.0: connectionpool_create_total
          expr: |
            rate(connectionpool_create_total{job="liberty", mp_scope="vendor"}[5m]) > 1
          for: 10m
          labels:
            severity: warning
            component: liberty
          annotations:
            summary: "High database connection churn on {{ $labels.pod }}"
            description: "Liberty pod {{ $labels.pod }} is creating {{ $value | printf \"%.2f\" }} new connections per second. High churn may indicate connection timeout issues, database restarts, or network instability."
